#!/bin/bash

# ============================================================================
#SBATCH --account=cwd01
#SBATCH --uenv=icon/25.2:v3:/user-environment
#SBATCH --view=default
#SBATCH --job-name=EXCLAIM_COUPLED
#SBATCH --output=LOG.EXCLAIM_COUPLED.%j
#SBATCH --error=LOG.EXCLAIM_COUPLED.%j
#SBATCH --time=00:15:00
#SBATCH --nodes=4
#SBATCH --gpus-per-node=4
#SBATCH --mem=0
#SBATCH --exclusive
# ============================================================================

# set -x

# ============================================================================
# CAUTION
# - Restart mechanism not implemented
# - Only initialiseOcean="fromClimatology" case

# ============================================================================
# Settings

# Get runscript path
# ------------------
RUNSCRIPT_PATH=$(scontrol show job "${SLURM_JOB_ID}" | awk -F= '/Command=/{print $2}')
RUNSCRIPT_DIR=$(cd $(dirname "${RUNSCRIPT_PATH}"); pwd)

# Target architecture
# -------------------
if [[ "$#" -lt 1 ]]; then
    echo "ERROR: ${0} requires at least one argument for the target architecture"
    echo "       which must be either 'cpu', 'cpu-cpu' or 'hybrid'"
    exit 1
fi
if [[ "${1}" != "cpu" ]] && [[ "${1}" != "cpu-cpu" ]] && [[ "${1}" != "hybrid" ]]; then
    echo "ERROR: ${0} first argument must be either 'cpu', 'cpu-cpu' or hybrid'"
    exit 1
fi
export TARGET="${1}"
shift
export RUN_OPTIONS=("$@")

export PROFILE=false
export SEPARATE_IO=false
for option in "${RUN_OPTIONS[@]}"; do
    if [ "$option" = "--profile" ]; then
        PROFILE=true
    elif [ "$option" = "--separate-io" ]; then
        SEPARATE_IO=true
    fi
done

# Case settings - 1 
# -----------------
# Some main settings depend on case settings and vice-versa
# so we need to source the case settings twice
export CASE="${CASE:-R02B07-R02B07}"
if [[ "${CASE}" != "R02B07-R02B07" ]] && [[ "${CASE}" != "R02B08-R02B09" ]] && [[ "${CASE}" != "R02B10-R02B10" ]]; then
    echo "ERROR: CASE must be either 'R02B07-R02B07', 'R02B08-R02B09' or 'R02B10-R02B10'"
    exit 1
fi
source "settings_${CASE}.sh"

# Load Auxiliary functions
# ------------------------
source run_utils/run_tools.sh
source namelists.sh
source inputs.sh

# Experiment name
# ---------------
export EXPNAME=${EXPNAME:-"EXCLAIM_coupled_${CASE}_${TARGET}"}

# Base ICON directory
# -------------------
export basedir=${basedir:-"${RUNSCRIPT_DIR}/../icon-hybrid"}

# Executables
# -----------
export icon_cpu=${icon_cpu:-"${basedir}/build-cpu/bin/icon"}
export icon_gpu=${icon_gpu:-"${basedir}/build-gpu/bin/icon"}

# Input data directories
# ----------------------
common_data_poolFolder="/capstor/store/cscs/userlab/cws01/input/icon/common"
icon_data_poolFolder="/capstor/store/cscs/userlab/cws01/input/icon/global/grids"
atmo_data_InputFolder="${icon_data_poolFolder}/atmo/${atmos_refinement}_${atmos_gridID}"
atmos_grid_folder="${icon_data_poolFolder}/atmo/${atmos_refinement}_${atmos_gridID}"
ocean_grid_folder="${icon_data_poolFolder}/ocean/${ocean_refinement}_${ocean_gridID}"

# Dates and intervals
# -------------------
export start_date=${start_date:-"1979-01-01T00:00:00Z"}

if [ "$PROFILE" = true ]; then
    export end_date=${end_date:-"1979-01-01T00:15:00Z"}
else
    export end_date=${end_date:-"1979-01-01T02:00:00Z"}
fi

lrestart=${lrestart:-.false.}
export checkpoint_interval=${checkpoint_interval:-${restart_interval}}

chunk_start_date=${chunk_start_date:-${start_date}}
chunk_end_date=$(date_cycle "${chunk_start_date}" "${restart_interval}" "${end_date}")

start_year=${start_date:0:4}
chunk_start_year=${chunk_start_date:0:4}
chunk_end_year=${chunk_end_date:0:4}

if [ "${chunk_start_year}" !=  "${chunk_end_year}" ]; then
    echo "ERROR: chunk ends in the different year than it starts"
    exit 1
fi

all_output_interval="PT300S"      # monthly output - production

# Type of experiment
# ------------------
export exptype=${exptype:-"control"} # "hist"
if [ "${exptype}" != "control" ] && [ "${exptype}" != "hist" ]; then
    echo "ERROR: unsupported experiment type: ${exptype}"
    exit 1
fi
export control_year=${control_year:-1979} # use 1850 for picontrol
# TODO: use ssp
ssp="370"
initialiseOcean="fromClimatology"    # ocean is setup from climatology, atmosphere + hdext cold-started from scratch

# namelist files
# --------------
master_namelist="icon_master.namelist"
atm_namelist="NAMELIST_${EXPNAME}_atm"
oce_namelist="NAMELIST_${EXPNAME}_oce"
lnd_namelist="NAMELIST_${EXPNAME}_lnd"


# Atmosphere settings
# -------------------
atmos_grid_target="icon_grid_${atmos_gridID}_${atmos_refinement}_G.nc"
atmo_model_equations=3 # equation system
#                     1=hydrost. atm. (T dynamics)
#                     2=hydrost. atm. (theta dynamics)
#                     3=non-hydrost. atm.,
#                    -1=shallow water model
#                    -2=hydrost. ocean

nlev=120          # nlev = number of full levels
iforcing=3

case "${exptype}" in
    "control")
        irad_aero=12
        ighg1=2    # const. vert. prof. of GHGs defined with vmr_* for CO2, O2, CFC11, CFC12
        ighg2=3    # tanh-profile with surface concentration given by vmr_ch4/n2o for CH4, N2O
        ;;
    "hist")
        irad_aero=18 # background aero. from Kinne + volcanic aero. + anthropogenic aero. from Simple Plume
        ighg1=4    # greenhouse gases from external file
        ighg2=4    # greenhouse gases from external file
        ;;
esac

# output intervals
atm_file_interval="P1M"
atm_output_interval=${all_output_interval}
atm_hfreq_output_interval="PT6H"

# Ocean settings
# --------------
ocean_grid_target="icon_grid_${ocean_gridID}_${ocean_refinement}_O.nc"
VERT_COR=1
ocean_vertical_levels="L72"
use_hamocc="no"
start_fx=${start_date}  # output time of geometry file fx

# output intervals
oce_file_interval="P1M"
oce_output_interval=${all_output_interval}
oce_output_interval_def="P1D"

# Case settings - 2 
# -----------------
# Some main settings depend on case settings and vice-versa
# so we need to source the case settings twice
source "settings_${CASE}.sh"

# Activate output streams
# -----------------------
export activate_output=${activate_output:-"true"}
export activate_output_dyamond=${activate_output_dyamond:-"false"}
if [[ "${activate_output}" != "true" ]];then
    ATM_IO_TASKS=0
    OCE_IO_TASKS=0
fi

# ============================================================================
# Input files
atm_inputs
lnd_inputs
oce_inputs

# ============================================================================
# Config files
compute_task_distribution_variables
create_multiprog_file

create_slurm_hostfile \
    --output_filepath "./hostfile-${SLURM_JOB_ID}" \
    --tot_tasks_per_node "${TOT_TASKS_PER_NODE}" \
    --atm_comp_tasks_per_node "${ATM_COMP_TASKS_PER_NODE}" \
    --atm_io_tasks "${ATM_IO_TASKS}" \
    --oce_io_tasks "${OCE_IO_TASKS}" \
    --threads_per_task "${CPUS_PER_TASK}" \
    --max_threads_per_node "$(grep -c ^processor /proc/cpuinfo)" || exit

export SLURM_HOSTFILE="$(pwd)/hostfile-${SLURM_JOB_ID}"

set_ocean_vertical_coordinate

icon_master_nml
coupling_yaml
atmo_nml
lnd_nml
oce_nml

if [[ "${activate_output}" == "true" ]];then
    coupled_streams
    
    # Dyamond output streams. Comment out to deactivate
    if [ "${activate_output_dyamond}" == "true" ]; then
        # NOTE: That could also be gathered in a function in the case-specific settings
        dyamond_stream_1_1
        dyamond_stream_1_2
        dyamond_stream_1_3
        dyamond_stream_1_4
        dyamond_stream_1_5
        dyamond_stream_2
        dyamond_stream_3 
        dyamond_stream_4
        dyamond_stream_5
        dyamond_stream_6
        dyamond_stream_7
        dyamond_stream_8
        dyamond_stream_9
        dyamond_stream_10
        dyamond_stream_11
        dyamond_stream_12
        dyamond_stream_13
        dyamond_stream_14
        #dyamond_stream_15_1
        #dyamond_stream_15_2
        #dyamond_stream_15_3
        #dyamond_stream_15_4
        #dyamond_stream_15_5
        #dyamond_stream_15_6
        #dyamond_stream_15_7
        #dyamond_stream_15_8
        #dyamond_stream_15_9
        #dyamond_stream_15_10
        #dyamond_stream_15_11
        #dyamond_stream_15_12
        #dyamond_stream_15_13
    fi
fi

# ============================================================================
# Executables
ln -sf ${icon_cpu} icon_cpu
ln -sf ${icon_gpu} icon_gpu

echo "ICON shared object dependencies"
ldd ${icon_cpu}
ldd ${icon_gpu}

# ============================================================================
# Run

# Run environment
# ---------------
set_environment

# MPI run
# -------
run_model

# Restart
# -------
restart_model
