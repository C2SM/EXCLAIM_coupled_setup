#!/bin/bash

# ============================================================================
#SBATCH --account=cwp07
#SBATCH --partition=tier0
#SBATCH --uenv=icon/25.2:v3:/user-environment
#SBATCH --view=default
#SBATCH --job-name=EXCLAIM_COUPLED
#SBATCH --output=LOG.EXCLAIM_COUPLED.%j
#SBATCH --error=LOG.EXCLAIM_COUPLED.%j
#SBATCH --time=00:15:00
#SBATCH --nodes=4
#SBATCH --gpus-per-node=4
#SBATCH --mem=0
#SBATCH --exclusive
# ============================================================================

# set -x

# ============================================================================
# CAUTION
# - Restart mechanism not implemented
# - Only initialiseOcean="fromClimatology" case

# ============================================================================
# Settings

# Get runscript path
# ------------------
RUNSCRIPT_PATH=$(scontrol show job "${SLURM_JOB_ID}" | awk -F= '/Command=/{print $2}')
RUNSCRIPT_DIR=$(cd $(dirname "${RUNSCRIPT_PATH}"); pwd)

# Target architecture
# -------------------
if [[ "$#" -lt 1 ]]; then
    echo "ERROR: ${0} requires at least one argument for the target architecture"
    echo "       which must be either 'cpu', 'cpu-cpu' or 'hybrid'"
    exit 1
fi
if [[ "${1}" != "cpu" ]] && [[ "${1}" != "cpu-cpu" ]] && [[ "${1}" != "hybrid" ]]; then
    echo "ERROR: ${0} first argument must be either 'cpu', 'cpu-cpu' or hybrid'"
    exit 1
fi
export TARGET="${1}"
shift
export RUN_OPTIONS=("$@")

export PROFILE=false
export SEPARATE_IO=false
for option in "${RUN_OPTIONS[@]}"; do
    if [ "$option" = "--profile" ]; then
        PROFILE=true
    elif [ "$option" = "--separate-io" ]; then
        SEPARATE_IO=true
    fi
done

if [ "$SEPARATE_IO" = true ] && [ "$TARGET" != "hybrid" ]; then
    echo "ERROR: Separate IO mode is only supported for the TARGET=hybrid."
    exit 1
fi

# Case settings - 1 
# -----------------
# Some main settings depend on case settings and vice-versa
# so we need to source the case settings twice
export CASE="${CASE:-R02B07-R02B07}"
if [[ "${CASE}" != "R02B07-R02B07" ]] && [[ "${CASE}" != "R02B08-R02B09" ]] && [[ "${CASE}" != "R02B10-R02B10" ]]; then
    echo "ERROR: CASE must be either 'R02B07-R02B07', 'R02B08-R02B09' or 'R02B10-R02B10'"
    exit 1
fi
source "settings_${CASE}.sh"

# Settings checks
if (( ((nproma_atm > 0) + (nblocks_c_atm > 0) + (nblocks_e_atm > 0)) != 1 )); then
    echo "ERROR: one and only one of nproma_atm, nblocks_c_atm, nblocks_e_atm can be > 0"
    exit 1
fi

# Load Auxiliary functions
# ------------------------
source ../run_utils/run_tools.sh
source namelists.sh
source inputs.sh

# Experiment name
# ---------------
export EXPNAME=${EXPNAME:-"EXCLAIM_coupled_${CASE}_${TARGET}"}

# Base ICON directory
# -------------------
export basedir=${basedir:-"${RUNSCRIPT_DIR}/../../icon-hybrid"}

# Executables
# -----------
export icon_cpu=${icon_cpu:-"${basedir}/build-cpu/bin/icon"}
export icon_gpu=${icon_gpu:-"${basedir}/build-gpu/bin/icon"}

# Input data directories
# ----------------------
common_data_poolFolder="/capstor/store/cscs/userlab/cws01/input/icon/common"
icon_data_poolFolder="/capstor/store/cscs/userlab/cws01/input/icon/global/grids"
atmo_data_InputFolder="${icon_data_poolFolder}/atmo/${atmos_refinement}_${atmos_gridID}"
atmos_grid_folder="${icon_data_poolFolder}/atmo/${atmos_refinement}_${atmos_gridID}"
ocean_grid_folder="${icon_data_poolFolder}/ocean/${ocean_refinement}_${ocean_gridID}"

# Dates and intervals
# -------------------
export start_date=${start_date:-"2020-01-01T00:00:00Z"}

if [ "$PROFILE" = true ]; then
    export end_date=${end_date:-"2020-01-01T00:15:00Z"}
else
    export end_date=${end_date:-"2020-01-01T02:00:00Z"}
fi

lrestart=${lrestart:-.false.}
export checkpoint_interval=${checkpoint_interval:-${restart_interval}}

chunk_start_date=${chunk_start_date:-${start_date}}
chunk_end_date=$(date_cycle "${chunk_start_date}" "${restart_interval}" "${end_date}")

start_year=${start_date:0:4}
chunk_start_year=${chunk_start_date:0:4}
chunk_end_year=${chunk_end_date:0:4}

if [ "${chunk_start_year}" !=  "${chunk_end_year}" ]; then
    echo "ERROR: chunk ends in the different year than it starts"
    exit 1
fi

# Type of experiment
# ------------------
export exptype=${exptype:-"control"} # "hist"
if [ "${exptype}" != "control" ] && [ "${exptype}" != "hist" ]; then
    echo "ERROR: unsupported experiment type: ${exptype}"
    exit 1
fi
export control_year=${control_year:-2020} # use 1850 for picontrol
# TODO: use ssp
ssp="370"
initialiseOcean="fromClimatology"    # ocean is setup from climatology, atmosphere + hdext cold-started from scratch

# namelist files
# --------------
atm_model_name="atmo"
oce_model_name="ocean"
master_namelist="icon_master.namelist"
atm_namelist="NAMELIST_${EXPNAME}_atm"
oce_namelist="NAMELIST_${EXPNAME}_oce"
lnd_namelist="NAMELIST_${EXPNAME}_lnd"


# Atmosphere settings
# -------------------
atmos_grid_target="icon_grid_${atmos_gridID}_${atmos_refinement}_G.nc"
atmo_model_equations=3 # equation system
#                     1=hydrost. atm. (T dynamics)
#                     2=hydrost. atm. (theta dynamics)
#                     3=non-hydrost. atm.,
#                    -1=shallow water model
#                    -2=hydrost. ocean

nlev=120          # nlev = number of full levels
iforcing=3

case "${exptype}" in
    "control")
        irad_aero=12
        ighg1=2    # const. vert. prof. of GHGs defined with vmr_* for CO2, O2, CFC11, CFC12
        ighg2=3    # tanh-profile with surface concentration given by vmr_ch4/n2o for CH4, N2O
        ;;
    "hist")
        irad_aero=18 # background aero. from Kinne + volcanic aero. + anthropogenic aero. from Simple Plume
        ighg1=4    # greenhouse gases from external file
        ighg2=4    # greenhouse gases from external file
        ;;
esac

# Ocean settings
# --------------
ocean_grid_target="icon_grid_${ocean_gridID}_${ocean_refinement}_O.nc"
VERT_COR=1
ocean_vertical_levels="L72"
use_hamocc="no"
start_fx=${start_date}  # output time of geometry file fx

# Task distribution
# -----------------
case "${TARGET}" in
    "hybrid")
        if [ "$SEPARATE_IO" = true ]; then
            export TOT_TASKS_PER_COMP_NODE=16
            export MAX_TASKS_PER_IO_NODE=${MAX_TASKS_PER_IO_NODE:-4}
        else
            export TOT_TASKS_PER_NODE=16
        fi
        export ATM_COMP_TASKS_PER_NODE=4
        export CPUS_PER_TASK=16
        ;;
    "cpu" | "cpu-cpu")
        export TOT_TASKS_PER_NODE=144
        export ATM_COMP_TASKS_PER_NODE=108
        export CPUS_PER_TASK=1
        ;;
esac

# Case settings - 2 
# -----------------
# Some main settings depend on case settings and vice-versa
# so we need to source the case settings twice
source "settings_${CASE}.sh"

# Activate output streams
# -----------------------
export activate_output=${activate_output:-"true"}
export activate_output_dyamond=${activate_output_dyamond:-"false"}
if [ "${activate_output}" == "true" ]; then
    [ "${activate_output_dyamond}" == "true" ] && atm_streams+=( "${dyamond_streams[@]}" )
    # For max parallelism, use 1 task per output stream
    export ATM_IO_TASKS=${ATM_IO_TASKS:-${#atm_streams[@]}}
    export OCE_IO_TASKS=${OCE_IO_TASKS:-${#oce_streams[@]}}
else
    ATM_IO_TASKS=0
    OCE_IO_TASKS=0
fi

# ============================================================================
# Input files
atm_inputs
lnd_inputs
oce_inputs

# ============================================================================
# Config files
compute_task_distribution_variables
create_multiprog_file

if [ "$SEPARATE_IO" = true ]; then
    create_slurm_hostfile_separate_io \
        --output_filepath "./hostfile-${SLURM_JOB_ID}" \
        --tot_tasks_per_comp_node "${TOT_TASKS_PER_COMP_NODE}" \
        --max_tasks_per_io_node "${MAX_TASKS_PER_IO_NODE}" \
        --atm_comp_tasks_per_node "${ATM_COMP_TASKS_PER_NODE}" \
        --atm_io_tasks "${ATM_IO_TASKS}" \
        --oce_io_tasks "${OCE_IO_TASKS}" \
        --threads_per_task "${CPUS_PER_TASK}" \
        --max_threads_per_node "$(grep -c ^processor /proc/cpuinfo)" || exit
else
    create_slurm_hostfile_load_balanced \
        --output_filepath "./hostfile-${SLURM_JOB_ID}" \
        --tot_tasks_per_node "${TOT_TASKS_PER_NODE}" \
        --atm_comp_tasks_per_node "${ATM_COMP_TASKS_PER_NODE}" \
        --atm_io_tasks "${ATM_IO_TASKS}" \
        --oce_io_tasks "${OCE_IO_TASKS}" \
        --threads_per_task "${CPUS_PER_TASK}" \
        --max_threads_per_node "$(grep -c ^processor /proc/cpuinfo)" || exit
fi

export SLURM_HOSTFILE="$(pwd)/hostfile-${SLURM_JOB_ID}"

set_ocean_vertical_coordinate

icon_master_nml
coupling_yaml
atmo_nml
lnd_nml
oce_nml

if [ "${activate_output}" == "true" ]; then
    for stream in "${atm_streams[@]}" "${oce_streams[@]}"; do
        if [ "$(type -t ${stream})" != "function" ]; then
           echo "function for output stream ${stream} not defined"
           exit 1
        fi
        ${stream}
    done
fi

# ============================================================================
# Executables
ln -sf ${icon_cpu} icon_cpu
ln -sf ${icon_gpu} icon_gpu

echo "ICON shared object dependencies"
ldd ${icon_cpu}
ldd ${icon_gpu}

# ============================================================================
# Run

# Run environment
# ---------------
set_environment

# MPI run
# -------
run_model

# Restart
# -------
restart_model
